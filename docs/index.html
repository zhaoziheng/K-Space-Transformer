<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->

<style type="text/css">
  @font-face {
   font-family: 'Avenir Book';
   src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
   }

  body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

	<title>K-Space Transformer for Undersampled MRI Reconstruction</title>
</head>

<body>
	<br>
	<center>
	<span style="font-size:36px">K-Space Transformer for Undersampled MRI Reconstruction</span><br><br><br>
	</center>
	<table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px">Ziheng Zhao</a><sup>1</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px">Tianjiao Zhang</a><sup>1,2</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
              <center>
                <span style="font-size:16px"><a href="https://weidixie.github.io/">Weidi Xie</a><sup>1,2</sup></span>
                </center>
                </td>
                    <td align="center" width="160px">
	            <center>
                <span style="font-size:16px"><a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a><sup>1,2</sup></span>
                </center>
		            </td>
                    <td align="center" width="160px">	    
              <center>
                <span style="font-size:16px"><a href="https://mediabrain.sjtu.edu.cn/">Yanfeng Wang</a><sup>1,2</sup></span>
                </center>
            </tr>

        </tbody></table><br>
	
	  <table align="center" width="700px">
            <tbody><tr>
                    <td align="center" width="50px">
              <center>
                    <span style="font-size:16px"></span>
                </center>
                </td>
                    <td align="center" width="300px">
              <center>
                    <span style="font-size:16px"><sup>1</sup>CMIC, Shanghai Jiao Tong University</span>
                </center>
                </td>
                    <td align="center" width="300px">
              <center>
                    <span style="font-size:16px"><sup>2</sup>Shanghai AI Laboratory</span>
                </center>
                </td>
        </tr></tbody></table>
	
	<table align="center" width="700px">
            <tbody><tr>
              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">Code
                    <a href="https://github.com/zhaoziheng/K-Space-Transformer"> [GitHub]</a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    Paper  <a href="https://arxiv.org/abs/2206.06947v2"> [arXiv]</a>
                  </span>
                </center>
              </td>

              <td align="center" width="200px">
                <center>
                  <br>
                  <span style="font-size:20px">
                    Cite <a href="./cite.txt"> [BibTeX]</a>
                  </span>
                </center>
              </td>
            </tr></tbody>
      </table>
	
      <br><hr>
      <center><h2> Abstract </h2> </center>
      <p style="text-align:justify; text-justify:inter-ideograph;">
      <left>
	      This paper considers the problem of undersampled MRI reconstruction. We propose a novel Transformer-based framework for directly processing signal in k-space, going beyond the limitation of regular grids as ConvNets do. As shown in the following figure, we adopt an implicit representation of k-sapce spectrogram, treating spatial coordinates as inputs, and dynamically query the sparsely sampled points to reconstruct the spectrogram, i.e. learning the inductive bias in k-space. To strike a balance between computational cost and reconstruction quality, we build the decoder with hierarchical structure to generate low-resolution and high-resolution outputs respectively. To validate the effectiveness of our proposed method, we have conducted extensive experiments on two public datasets, and demonstrate superior or comparable performance to state-of-the-art approaches. 
      </left></p>
      <table align="center" width="800px">
            <tbody><tr>
              <td align="center" width="600px">
                <center>
                  <img style="width:700px" src='./resources/teaser.jpg'></img>
                </center>
              </td>
            </tr></tbody>
      </table>
	
      <br><hr>
      <center> <h2> Method </h2> </center>
      <p style="text-align:justify; text-justify:inter-ideograph;"><left>
	  Illustration of the proposed K-Space-Transformer.
	  (a) The structure of Encoder. The goal of the Encoder is to compute a compact feature representation for the sampled frequency bins in k-space.
	  (b) The structure of Decoder. The Decoder aims to reconstruct MRI by alternating completion in k-space and reﬁnement in image domain.
	  (c) The overall framework of the K-space Transformer. In practice, we adopt a hierarchical decoder to strive a balance between the computational cost and performance trade-oﬀ.
	</left></p>
        <table align="center" width="800px">
            <tbody><tr>
              <td align="center" width="600px">
                <center>
                  <img style="width:700px" src='./resources/framework.jpg'></img>
                </center>
              </td>
            </tr></tbody>
      </table>
      <br>
      <hr>

      <center><h2>Results</h2></center>
      <p><b>R1: Compared with baselines</b> </p> 
      <p>Quantitative comparison with baselines on 1D sampling pattern</p>

      <table align="center" width="800px">
            <tbody><tr>
              <td align="center" width="600px">
                <center>
                  <img style="width:600px" src='./resources/1d_tab.png'></img>
                </center>
              </td>
            </tr></tbody>
      </table>

      <p>Quantitative comparison with baselines on 2D sampling pattern</p>
      <table align="center" width="800px">
            <tbody><tr>
              <td align="center" width="600px">
                <center>
                  <img style="width:700px" src='./resources/2d_tab.png'></img>
                </center>
              </td>
            </tr></tbody>
      </table>
      <p>Qualitative comparison of 5× acceleration on diﬀerent sampling patterns. Brighter means higher error.</p>
      
      <table align="center" width="800px">
            <tbody><tr>
              <td align="center" width="600px">
                <center>
                  <img style="width:600px" src='./resources/5x_vis.png'></img>
                </center>
              </td>
            </tr></tbody>
      </table>
	
      <p><b>R2: Ablation Study </b> </p>	
	<div class="container">
		<div class="image">
			<img style="width:450px" src='./resources/ab_tab.png'></img>
		</div>
		<div class="text"> 
			<p> We remove the image domain reﬁnement module (RM), and the LR decoder(LRD) sequentially on OASIS dataset to investigate the eﬀectiveness of hybrid learning and the hierarchical structure.
			</p>
		</div>
	</div>

  <p><b>R3: Analysis on intermedia results</b> </p> 
      <p>We visualize some intermedia results of K-Space Transformer: LR denotes the reconstruction output of LR decoder; Upsampled denotes the up-sampled result of that; HR and HR(woRM) refer the output of HR decoder and that without refinement module</p>

      <table align="center" width="800px">
            <tbody><tr>
              <td align="center" width="600px">
                <center>
                  <img style="width:610px" src='./resources/inter_vis.png'></img>
                </center>
              </td>
            </tr></tbody>
      </table>
      
      <center> <h2> Acknowledgements </h2> </center>
      <p> 
	      Based on a template by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>.
      </p>
      <br>


<br>
</body>
</html>
